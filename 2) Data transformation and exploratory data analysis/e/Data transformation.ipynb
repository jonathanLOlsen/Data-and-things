{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7cd4032-4d69-413a-a405-5913958099db",
   "metadata": {},
   "source": [
    "# Data Transformation\n",
    "\n",
    "In this notebook, we look into some of the central data transformation techniques. For more data transformation techniques, see the book [Python for Data Analysis, 3E](https://wesmckinney.com/book/) by Wes McKinney."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d77c967b-5932-4f3b-9fd8-7d1a0619eece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65bcc3a-0d30-4e43-b869-45d051aa26c1",
   "metadata": {},
   "source": [
    "## Grouping and aggregation\n",
    "\n",
    "Sometimes we want to calculate various functions on particular subgroups of a dataset. For instance, in the exercise last time, we asked the following question for the \"adult\" dataset: *\"Is the average hours per week (worked) different across different marital-status groups?\"*. That is, we asked for the average of `hours-per-week` for each categorical value of the variable `marital-status`. Such calculations are common and easily done using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30c351f-4488-4a83-ab0b-58f33f080889",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "adult = fetch_ucirepo(id=2) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = adult.data.features \n",
    "y = adult.data.targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658112c7-f187-48d8-aaaa-a84437b28f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9558156f-d397-49ee-bfb3-bf148229f31e",
   "metadata": {},
   "source": [
    "To get the mean hours-per-week per marital-status, we can take out the `hours-per-week` column and group it by the `marital-status` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea6ab41-29ec-4630-a4da-d96cc3c93d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "hgbm = X[\"hours-per-week\"].groupby(X[\"marital-status\"])\n",
    "hgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d95bf5-4bbd-46d2-ad0f-801a57440dbb",
   "metadata": {},
   "source": [
    "This will give us a grouped object. We can now aggregate the `hours-per-week` for each marital status using various functions (methods) such as mean or median:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3052dc-3ed6-49c9-8b1a-4fa9765d60c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hgbm.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7694add0-e9a9-4974-ade4-aa17b0e22aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "hgbm.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91c5076-4862-4825-81b7-5a9e44396933",
   "metadata": {},
   "source": [
    "We can also count how many cases there are in each group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22407a6f-333a-4a66-b85a-f9fde0f57fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hgbm.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5713f6c1-9b42-48bb-8f8c-2996d20f4677",
   "metadata": {},
   "source": [
    "Or get several describtive statics at once using `describe`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4f843d-d265-41bd-8b47-0ed24c28aee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hgbm.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e70ca20-1fce-4ee3-91cc-ade62a5346b4",
   "metadata": {},
   "source": [
    "We can also group by multiple categorical variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e841eb-9f77-4c7b-88b8-d4bf747114ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "hgbmg = X[\"hours-per-week\"].groupby([X[\"marital-status\"], X[\"sex\"]])\n",
    "hgbmg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a4daf1-ba3e-47da-a29b-4b4b2e1f4a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "hgbmg.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7320c5f3-c397-4d52-9c4f-277090c14587",
   "metadata": {},
   "outputs": [],
   "source": [
    "hgbmg.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f53a16-d850-46d1-a122-8264c97eeea6",
   "metadata": {},
   "source": [
    "We can also group the entire dataframe by a categorical variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4143a627-7511-421e-bba4-e2aee65606ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xg = X.groupby(\"marital-status\")\n",
    "Xg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c4fa2e-bea3-4bc8-8100-bc53cbdce592",
   "metadata": {},
   "source": [
    "We can then subset specific columns and aggregate those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3352a678-b874-4f09-a8c6-b1657b2a6ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xg[\"age\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29b50af-8a88-4ee7-a1cd-0146d929e636",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xg[[\"age\", \"hours-per-week\"]].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543d4e27-d926-4b58-83f0-d921fe9311b3",
   "metadata": {},
   "source": [
    "Or calculate aggregations of all nummeric columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f782e7-b452-45cd-a607-d1e1076625d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xg.mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3587ed-c8d9-4c4d-8fe5-61aedf7bfd41",
   "metadata": {},
   "source": [
    "### Aggregating with abitrary functions\n",
    "\n",
    "`mean`, `median`, ... etc. are some of the most common statistical functions and they are explicit methods on the DataFrames and Series. However, sometimes one wants to aggregate by another function that is not a method on the DataFrame or Series. This functionality is also possible in pandas.\n",
    "\n",
    "For instance, you might want to calculate the range of a variable, that is the max value minus the min value. To do this, we first create the function we want to aggregate by (in this case range), and then use the `agg` method on the grouped object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d00cf40-6481-476f-8671-b24acece05cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_range(x):\n",
    "    return (x.max() - x.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25480e8f-ce2a-45f3-b5bf-826234d445d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xg[[\"age\"]].agg(data_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d7da8b-7c90-4c5f-90dd-c22d33982141",
   "metadata": {},
   "source": [
    "Or if we want to apply it on the entire dataframe we need the range function to check for numeric type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711db678-50e0-4be8-8f9c-4bd0cc67027a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "def data_range(x):\n",
    "    if is_numeric_dtype(x):\n",
    "        return (x.max() - x.min())\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "Xg.agg(data_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc1ec3a-5528-43bb-bde9-6abd849c5510",
   "metadata": {},
   "source": [
    "You can also use `agg` to get the aggregation by multiple functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8a57c6-4a76-4b70-bdd0-5670f74deedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xg[[\"age\"]].agg([np.mean, np.median, np.std])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cd2131-140e-49ae-bd40-84e80ae6c594",
   "metadata": {},
   "source": [
    "Or if you want the columns named:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817b72b9-0575-4bd3-b0f0-13345bda6f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xg[[\"age\"]].agg([(\"Mean age\", np.mean), (\"Median age\", np.median), (\"Standard deviatio of age\", np.std)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd361b07-84ef-47dd-93f2-1bf8cf0045f9",
   "metadata": {},
   "source": [
    "As these aggregation functions are also methods on the dataframe, as the warning tell us, we can just write `\"mean\"` instead of `np.mean` for instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4abcd2a-0936-4384-bb82-31337dcc750b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xg[[\"age\"]].agg([(\"Mean age\", \"mean\"), (\"Median age\", \"median\"), (\"Standard deviatio of age\", \"std\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f30916",
   "metadata": {},
   "source": [
    "## Joins\n",
    "\n",
    "Sometimes our data comes in multiple dataframes or tables, and we want to combine them into one for doing machine learning, for instance. We use joins just like in SQL to do this in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cc2474",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({\"key\": [\"b\", \"b\", \"a\", \"c\", \"a\", \"a\", \"b\"], \"data1\": pd.Series(range(7), dtype=\"Int64\")})\n",
    "\n",
    "df2 = pd.DataFrame({\"key\": [\"a\", \"b\", \"d\"], \"data2\": pd.Series(range(3), dtype=\"Int64\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84a33af-3932-4a5b-b5bd-ef793a0e4f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d999afd-710a-4731-abf4-5478642340a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f42200",
   "metadata": {},
   "source": [
    "The `merge` function from Pandas do an inner join:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05514153",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df1, df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d3a641",
   "metadata": {},
   "source": [
    "Specifying keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8354ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df1, df2, on=\"key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d72c4f2-85f5-487f-99ba-40d4d97b124b",
   "metadata": {},
   "source": [
    "If the key is named differently in the two dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112385fc-9053-42cd-8275-c361e4f90fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.rename(columns={\"key\": \"key_other\"})\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab7895d-73ce-4170-a5b1-da8dfc157330",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fcf743",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df1, df3, left_on=\"key\", right_on=\"key_other\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769dc619",
   "metadata": {},
   "source": [
    "Doing an outer, left or right join:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e38bd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df1, df2, on=\"key\", how = \"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79eeee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df1, df2, on=\"key\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f3d787",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df1, df2, on=\"key\", how = \"right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bbb00e-5144-4e1b-97cd-85da0890e7fe",
   "metadata": {},
   "source": [
    "### Using indexes for joins\n",
    "\n",
    "Sometimes the keys we want to join on are in the indexes of the data frames instead of in a column. To join, we can just turn the index into a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f162132b-c6c1-47dd-8bed-fe5d64d53480",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df1.set_index('key')\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d24294-89b2-4e4c-9e73-91101898a00b",
   "metadata": {},
   "source": [
    "As you can see above, `df4` contains the keys in the index. We can move the indexes into a column using `reset_index`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b690b5-5658-4f34-a080-d3a67d828d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df4.reset_index()\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b3092c-27a5-44d4-94a4-b2340513af5f",
   "metadata": {},
   "source": [
    "Now we can merge as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34009d86-bf96-475d-a7b9-26188e877ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df4, df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de8e810-3d2a-4352-85b1-611b2aae2d7c",
   "metadata": {},
   "source": [
    "## Pivoting\n",
    "\n",
    "Sometimes we want to make our dataframe wider or longer, that is move information between the columns names and the column values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7a8821-3028-46dd-bb6b-b8dd737e5556",
   "metadata": {},
   "source": [
    "### Pivoting long to wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b87462e-3b54-4cf5-ae7e-baa030a81468",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df = pd.DataFrame({\"student_id\" : [1,1,2,2,2,3,3],\n",
    "                       \"class\" : [\"algebra\", \"databases\",\"algebra\", \"databases\", \"creative writing\", \"algebra\", \"databases\"],\n",
    "                       \"grade\" : [7, 10, 4, 2, 10, 4, 12]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca5ef83-83ad-49af-a5dd-67a17d8b9904",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a361188-ba72-4521-b52e-fc8db56df56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09eaa45-4fdb-4f7f-ba0e-0706e9da4c88",
   "metadata": {},
   "source": [
    "We want to make it \"wider\", in the sense that we want one row per student, and then a column for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a54c2e-ecee-457b-a59b-1fc425a766c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df.pivot(index = \"student_id\", columns=\"class\", values=\"grade\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37396f5-350d-4375-b930-47300e2a08cf",
   "metadata": {},
   "source": [
    "Note that the ´student_id´ column is turned into the index. If we want to keep it as a column we can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff2bb40-3a66-472f-9de4-7f8ba71167b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df.pivot(index = \"student_id\", columns=\"class\", values=\"grade\").reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c2c59a-3d10-4815-b33d-ee4683bf3d64",
   "metadata": {},
   "source": [
    "The metod `pivot_table` is a more general method that allow for more functionality if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce6924b-3e1f-4173-ac51-29f34751fc72",
   "metadata": {},
   "source": [
    "### Pivoting wide to long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d65ce5b-3309-4619-a6c3-6758568e2d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_df = pd.DataFrame({\"Country\" : [\"Denmark\", \"Denmark\", \"Sweden\", \"Sweden\"],\n",
    "                       \"Type\" : [\"population\", \"infected\", \"population\", \"infected\",],\n",
    "                       \"2001\" : [5000, 1, 9500, 2],\n",
    "                       \"2002\" : [5050, 3, 9550, 4],\n",
    "                       \"2003\" : [5100, 6, 9650, 8],\n",
    "                       \"2004\" : [5150, 10, 9700, 9]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db674bb-e736-45b7-9a3b-6d059c19f323",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063f0175-3ee4-477a-a1f6-d7ad7c41328e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_df.melt(id_vars = [\"Country\", \"Type\"], value_vars = [\"2001\", \"2002\", \"2003\", \"2004\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd53f775-9f74-43d3-a41f-d3b9812d548c",
   "metadata": {},
   "source": [
    "You might want to rename the `variable` and  `value` column afterwards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e3d6d1-88d8-4bdb-86d6-9893dbf8df92",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_df.melt(id_vars = [\"Country\", \"Type\"], value_vars = [\"2001\", \"2002\", \"2003\", \"2004\"]).rename(columns={\"variable\": \"Year\", \"value\": \"Size\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8895434-63c2-44df-96b7-6bb642b8ed4d",
   "metadata": {},
   "source": [
    "## Creating new columns from mapping\n",
    "\n",
    "We can easily create a new column with a high-level categorization from a column that might have more values using the mapping functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee79fefd-88a7-4216-bca8-d75190b55052",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"food\": [\"bacon\", \"pulled pork\", \"bacon\",\n",
    "                              \"pastrami\", \"corned beef\", \"bacon\",\n",
    "                              \"pastrami\", \"honey ham\", \"nova lox\"],\n",
    "                     \"ounces\": [4, 3, 12, 6, 7.5, 8, 3, 5, 6]})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62bea19-ff26-4b87-9f19-7240a12c0530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dictionary mapping\n",
    "meat_to_animal = {\n",
    "  \"bacon\": \"pig\",\n",
    "  \"pulled pork\": \"pig\",\n",
    "  \"pastrami\": \"cow\",\n",
    "  \"corned beef\": \"cow\",\n",
    "  \"honey ham\": \"pig\",\n",
    "  \"nova lox\": \"salmon\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2aa7ab-f99c-4665-a611-3a700ce53417",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"food\"].map(meat_to_animal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8d2c63-d08d-4303-8756-cf8d93dbb93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"animal\"] = data[\"food\"].map(meat_to_animal)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44c606b-5c50-4e8e-8a00-b14c39943260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to do the mapping (here based on the dictionary!)\n",
    "def get_animal(x):\n",
    "    return meat_to_animal[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348b0852-f2dd-489f-adf0-c0976dd9992e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(\"animal\", axis = 1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74eea3e-d5b7-4733-bfb2-6867a53c0f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"animal\"] = data[\"food\"].map(get_animal)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753b11b7-5469-4806-b2ff-6b6e032794e9",
   "metadata": {},
   "source": [
    "## Transforming a categorical variable into dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df99ef36-76b0-445b-80eb-445d94d07b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a5f4ef-8a6f-4093-80cf-2c557cf390cf",
   "metadata": {},
   "source": [
    "Let us turn the categorical variable `animal` into dummy variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e06423-c528-4703-b72a-3e493e8b6959",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(data[\"animal\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0addeceb-0bd0-4e26-9098-6b2b4708c357",
   "metadata": {},
   "source": [
    "If we want the values to be 0 and 1 (int or float):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58a9b05-f305-48b6-8555-b9d852ae429e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(data[\"animal\"], dtype = \"int\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed8a1a5-bdc9-4679-95cb-58672f9ba1ee",
   "metadata": {},
   "source": [
    "If we want to add the dummies to the original dataframe we can do the following steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2598d83-b59a-4af5-a3a7-406485c60fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(data[\"animal\"], prefix=\"dummy\", dtype=float)\n",
    "dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcee8d64-09f5-4672-88b4-6cf8c8424d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_dummies = data.join(dummies)\n",
    "data_with_dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae976da5-0829-47eb-bfc5-2b501cb4932b",
   "metadata": {},
   "source": [
    "We might want to drop the original column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18de35d-881c-403b-b792-f04f9120b636",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_dummies = data_with_dummies.drop(\"animal\", axis = \"columns\")\n",
    "data_with_dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d8c650-f87a-4e08-a573-0f6ce32edb0a",
   "metadata": {},
   "source": [
    "**Note: When training machine learning models, it is often problematic if multiple column perfectly correlates. Here `dummy_cow` perfectly correlates with the two columns `dummy_pig` and `dummy_salmon`, in the sense that `dummy_cow = 1 - dummy_pig - dummy_salmon`. Thus one usually drops one of the dummy columns.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bd1bfa-5573-4401-9e47-30031d6dbcea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
