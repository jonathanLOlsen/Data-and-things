{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6bc904fe-92fa-49f2-8b12-050b08ecbfb1",
   "metadata": {},
   "source": [
    "# Convolutional Neural networks\n",
    "\n",
    "In this notebook, we will look closer at Convolutional Neural networks (CNN) for image classification. We will show how a CNN can improve our previous model for classifying handwritten digits in the MNIST dataset. This is based on the following code example from the keras website: [https://keras.io/examples/vision/mnist_convnet/](/https://keras.io/examples/vision/mnist_convnet/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4a428f-e079-4533-914f-8ec6c03902f9",
   "metadata": {},
   "source": [
    "First, however, we will redo the model from chapter 2 of the book. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104f1736-ed9d-419c-9db0-f2d320ed1c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3e8961-15f0-4c57-8878-66c17fd383af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74179eb6-5f00-4df8-9c19-b99225863b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31974bf8-ee87-42b7-ba50-b4be3f804b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b50d4b-56f3-4b92-be38-9fb6bb20c3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383138b7-cd84-4f96-80fd-f489374ffe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425b1a01-3406-4149-9b72-2edfd4e02efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0373cd3-9c06-4efd-8c4b-ba002ad308dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f\"test_acc: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982178f3-b7f9-4099-be2a-ff95f1cdcea1",
   "metadata": {},
   "source": [
    "## Building a CNN model for the MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85458e48-4a73-476a-96cd-e187111643cb",
   "metadata": {},
   "source": [
    "Now, let us build a CNN model on the same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b3d05e-3c5f-4d66-9cd0-5f9c8135cc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636669e8-2446-45e3-a448-4bb55bfe530d",
   "metadata": {},
   "source": [
    "Before we can train it, we need the data in the right format for CNN. For CNN models, we do not need to reshape or flatten our images thus, the only preprocessing we need is the one below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537d4325-75cc-4ce5-be70-7b1270130fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8945a63-0c78-4dca-90b7-5c1089a5a7fa",
   "metadata": {},
   "source": [
    "Now, let us train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358fc952-e6c9-40af-a2bc-3244366aed10",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 15\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189e9cad-2f73-430a-b2da-5a6cb9a6411f",
   "metadata": {},
   "source": [
    "Finally, we can evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c08af2-1514-4645-9fab-4b9d364aa996",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c2c505-46d1-4c0a-8e4c-32206c5a4c72",
   "metadata": {},
   "source": [
    "Our original model was already fairly good, but we managed to improve it relatively significantly, to a production quality. However, the CNN model took much longer to train, which also have to be taken into account. In other, more complicated image classification tasks, CNNs have turned out to be really well performing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9ff809-fa67-48e0-a4f2-34fca0124bc7",
   "metadata": {},
   "source": [
    "## Cat vs dog CNN\n",
    "\n",
    "In this section we will look at building a CNN to classify images of cats or dogs. It is based on a famous kaggle dataset available here: [https://www.kaggle.com/c/dogs-vs-cats/data](https://www.kaggle.com/c/dogs-vs-cats/data). We will, however, only look at a small subset of the dataset (1200 training images, 200 validation images, and 600 test images), which is also available on the course moodle page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc95dfbf-767c-435b-a2b1-bffd31c2fc19",
   "metadata": {},
   "source": [
    "We first need to load the various datasets in (and process them properly). Luckily, Keras has utility functions that makes this easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274b62a2-a1b6-4c08-9391-11bf9f1cad5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    \"dogs_vs_cats_tiny/train\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)\n",
    "validation_dataset = image_dataset_from_directory(\n",
    "    \"dogs_vs_cats_tiny/validation\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    \"dogs_vs_cats_tiny/test\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf761cb-6a66-42d4-b7ac-fd1ffe3e8ce4",
   "metadata": {},
   "source": [
    "Let us now build a CNN models to classify cats vs dogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e107bea-3ad5-48ba-b87f-e47f30b6173c",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_and_d_model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(180, 180, 3)),\n",
    "        layers.Rescaling(1./255),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(128, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(256, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "c_and_d_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35b47d6-2389-4776-8e88-fe3b7346b2a4",
   "metadata": {},
   "source": [
    "And let us compile it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0854b4e-da02-4b35-af6b-c87dfc138bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_and_d_model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"rmsprop\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e92824d-e540-4769-8da4-5e893f7d5281",
   "metadata": {},
   "source": [
    "And let us finally fit it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50ec839-10b9-4d13-8607-636522602470",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = c_and_d_model.fit(\n",
    "    train_dataset,\n",
    "    epochs=8,  # I have already checked when to stop...\n",
    "    validation_data=validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcd9a37-5cc8-4e4a-8b5a-bbd7208ab599",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = history.history[\"accuracy\"]\n",
    "val_accuracy = history.history[\"val_accuracy\"]\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "epochs = range(1, len(accuracy) + 1)\n",
    "plt.plot(epochs, accuracy, \"bo\", label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_accuracy, \"b\", label=\"Validation accuracy\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dbb8af-6dba-4440-9da4-619ab764f90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = c_and_d_model.evaluate(test_dataset)\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f18d9b2-314e-48b5-aadb-27145c1ca7e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
